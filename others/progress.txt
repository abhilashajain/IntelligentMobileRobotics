NOTE : Just create a python file and complete the assignment, while submitting use the VishwakarmaS.py to follow the assignment guidlines

# Assignment 3


Part 1:

Navigation In the Lab LNG210

  roslaunch VishwakarmaS assign3_bringup.launch
  roslaunch VishwakarmaS assign3_navigation.launch  # touchdown.py

  Youtube:
    TurtleBot Navigating Through Goal Locations - https://www.youtube.com/watch?v=swwSebC-2J0
    TurtleBot Navigating Through Door (Going through the door only if its open) - https://www.youtube.com/watch?v=JJ5ceWMy5I8


Part 2:

Voice Navigation outside Lab LNG210

  roslaunch VishwakarmaS assign3_bringup.launch
  roslaunch VishwakarmaS assign3_voice.launch  # obeyer.py

  Youtube:
    TurtleBot Voice Navigation - https://www.youtube.com/watch?v=BUEU2VML0ss

  Note:
      We tried using the "google api" to recognize the voice commands.
      It was very slow and api response where taking a lot of time thus resulting in jerking motion of turtlebot.

      We also tried "pocketsphinx", using the https://github.com/shiqizhang6/ros_voice_control package,
      Here the recognition was quick but process was prone to surrounding noices and not recognizing different pronunciations.

      We also implemented a dialog system where it ask 'Yes' or 'No' before performing in commanded motion action.
      To see the dialog system code, Please checkout commit e49c90affe2744f27925e98ea5bc096cca37d6d3



Assignment 4

To Launch Aster camera:

Step 1 :: roslaunch turtlebot_bringup minimal.launch --screen

Step 2 :: roslaunch astra_launch astra.launch --screen

Step 3 :: rosrun image_view image_view image:=/camera/rgb/image_raw (change the topic according to need)
          you can also run multiple views at same time


Installations ::

# sudo apt-get install python-opencv

# sudo apt-get install ros-kinetic-cv-bridge

# sudo apt-get install ros-kinetic-vision-opencv

Also ROS PKG Install :: cv_bridge, vision_opencv, image_transport

watch -n1 rostopic echo /my_topic/field_name

Note : Red with aster camera is not Red I have added images


Links ::

Ball tracking with OpenCV
https://www.pyimagesearch.com/2015/09/14/ball-tracking-with-opencv/

ROS OpenCV Image Processing (Python) This is Helpful
https://industrial-training-master.readthedocs.io/en/melodic/_source/session5/OpenCV-in-Python.html

OpenCV with ROS using Python Very Helpful
https://dabit-industries.github.io/turtlebot2-tutorials/14b-OpenCV2_Python.html


Running coursing.py

launch bringup, astra


Coding ::
opencv split rgb to b,g,r
opencv split hsv to v,s,h

so in hsv version of rgb red_circle.jpeg threshold are

for v > 60
for s > 60
for h > 60

we are able to drow circle to red in video stream

try if ther is time to do same with ir senson




Image Not being displayed ::

rosrun VishwakarmaS coursing.py
[INFO] [1573240241.797955]: seq: 0
stamp:
  secs: 1573240241
  nsecs: 754485123
frame_id: "camera_rgb_optical_frame"

Dont run a window in OpenCV Just access the topic and get the
camera data and then porcess it and send control command to publisher topic
Use the pring data to detect the boll and move robot


# Assignment 4


TurtleBot Follows a Ball Based on Visual Input (RGB-D)

Run Command : roslaunch VishwakarmaS assign6.launch

Youtube : TurtleBot Ball Follower - https://youtu.be/FKLasmc6CHo


Reference :

Ball tracking with OpenCV
https://www.pyimagesearch.com/2015/09/14/ball-tracking-with-opencv/

Red Ball Image "/others/aster_red.jpg" when ROS topic "/camera/rgb/image_raw" data is saved to jpg file

Note:
    We used the open source tutorial to track a ball using camera frames.
    We then implemented the same using aster data from topic.
    The Red Ball appears blue when we tried to save the numpy data from the ros topic to a jpg image file.
    we made modification in our code to track the ball motion and added motion commands based on ball motion.
